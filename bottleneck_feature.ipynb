{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch resnet网络的bottleneck 特征提取\n",
    "1. 直观的方法，详见[这里](https://discuss.pytorch.org/t/how-can-l-use-the-pre-trained-resnet-to-extract-feautres-from-my-own-dataset/9008/4)\n",
    "2. 优雅的方法是使用类函数来获得bottleneck层，详见[这里](https://forums.fast.ai/t/pytorch-best-way-to-get-at-intermediate-layers-in-vgg-and-resnet/5707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# print (dir(model))\n",
    "print((model.named_parameters)) #同model.parameters， model.children,只是bound method Module.${name} of ResNet 不同\n",
    "# print (list(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_feature = nn.Sequential((*list(model.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (bottleneck_feature.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedding=Variable\n",
    "def copy_data(m, i, o):\n",
    "            my_embedding =o.data.squeeze()\n",
    "        \n",
    "model.layer4[0].conv2.register_forward_hook(copy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='3.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 394)\n"
     ]
    }
   ],
   "source": [
    "toTensor = transforms.ToTensor()\n",
    "\n",
    "def prepare_image(file):\n",
    "    image = Image.open(file)\n",
    "    print(image.size)\n",
    "    # size = (244,244)  #任意大小\n",
    "    # img = image.resize(size , Image.BILINEAR)\n",
    "    img = toTensor(image)\n",
    "    img = img.sub_(0.5).div_(0.5)\n",
    "    img = img.view(1, *img.size())\n",
    "    return img\n",
    "img = prepare_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = bottleneck_feature(img)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8916, 0.9683, 0.8634, 1.0349, 0.8481, 0.7674, 0.8648, 1.0380, 0.9475,\n",
       "        0.9245, 0.8767, 0.8676, 0.8809, 0.9311, 0.8718, 0.9117, 0.8710, 1.3772,\n",
       "        0.8684, 0.8540, 0.8693, 1.0411, 0.9136, 0.9373, 0.9276, 0.9305, 0.9564,\n",
       "        0.9462, 0.8380, 0.8828, 0.8104, 0.8221, 0.8057, 0.8248, 0.8901, 0.8975,\n",
       "        0.8672, 0.9389, 0.8854, 0.8745, 0.8394, 0.8409, 0.8498, 0.9558, 0.8298,\n",
       "        0.9022, 0.9087, 1.1222, 0.8818, 0.8251, 0.9145, 0.9441, 0.8581, 0.8835,\n",
       "        0.9302, 0.8793, 1.0677, 0.9063, 1.0129, 0.9507, 0.8713, 0.8485, 0.9283,\n",
       "        0.8489, 0.8641, 1.0184, 0.8738, 0.8673, 0.9285, 0.8730, 0.8702, 0.7891,\n",
       "        0.8495, 0.8091, 0.9184, 0.8480, 0.8120, 0.8730, 0.8894, 0.8823, 0.8747,\n",
       "        0.9346, 1.0223, 1.1561, 0.8316, 0.9479, 0.9101, 0.8574, 0.9358, 0.8261,\n",
       "        0.7527, 0.8891, 0.8231, 0.9558, 0.8394, 0.7938, 0.8856, 0.8802, 0.9016,\n",
       "        0.8664, 0.9691, 1.0150, 0.9257, 0.9472, 0.9089, 0.7865, 0.8724, 0.8968,\n",
       "        0.7964, 0.8742, 0.8628, 0.8773, 0.8295, 0.8705, 0.8435, 0.8666, 0.9392,\n",
       "        0.8908, 0.9201, 0.9771, 0.9633, 0.8837, 0.8562, 0.8440, 0.8624, 0.7522,\n",
       "        0.8511, 0.9078, 0.8802, 0.9596, 0.9035, 0.8937, 0.8145, 0.8641, 1.0010,\n",
       "        0.9916, 0.8464, 0.9096, 0.8334, 0.8682, 0.9053, 0.9075, 0.9377, 0.8377,\n",
       "        0.8565, 0.7755, 0.8212, 0.9327, 0.8347, 1.0785, 0.8915, 0.9101, 0.9211,\n",
       "        0.8672, 0.8416, 0.8431, 0.9480, 0.8957, 0.8493, 0.8827, 0.8561, 1.1677,\n",
       "        0.9511, 1.3470, 0.8510, 0.9526, 0.9441, 0.8583, 0.8689, 0.9226, 0.8931,\n",
       "        0.8494, 0.8868, 0.8383, 0.9305, 0.8348, 0.9127, 0.8102, 1.0313, 0.8545,\n",
       "        0.8463, 0.9168, 1.2458, 0.9473, 0.9972, 0.9543, 0.8489, 0.9453, 0.8780,\n",
       "        0.8587, 0.8626, 0.8393, 0.9060, 1.0768, 0.8350, 0.8412, 0.8950, 0.8573,\n",
       "        0.9209, 0.8239, 0.8711, 0.8380, 1.1105, 0.8637, 1.0606, 0.8610, 0.8058,\n",
       "        0.8609, 0.8690, 0.9452, 0.7931, 0.7886, 0.8619, 0.9654, 0.9059, 0.8357,\n",
       "        0.9364, 0.8240, 0.8175, 0.9684, 0.8443, 0.9856, 0.8360, 0.8450, 0.9072,\n",
       "        0.8387, 0.9831, 0.8866, 1.0367, 0.8979, 0.9102, 0.9214, 0.7809, 0.9189,\n",
       "        0.8460, 0.8951, 0.9068, 0.8915, 0.8443, 0.9875, 0.8807, 0.8769, 0.9687,\n",
       "        0.7883, 0.8721, 0.9400, 0.9376, 0.8145, 0.8684, 0.9767, 0.9942, 0.9110,\n",
       "        0.8908, 0.8817, 0.8889, 1.2596, 0.8616, 1.0236, 0.9372, 0.9780, 0.9084,\n",
       "        0.8998, 0.8856, 0.8938, 0.8265, 0.9138, 0.8481, 0.8435, 0.8900, 0.9065,\n",
       "        0.9128, 0.8774, 0.8661, 0.8507, 0.9030, 0.8736, 0.9030, 0.8311, 0.8905,\n",
       "        0.7986, 1.1912, 0.7806, 0.8746, 0.8788, 0.9569, 0.8713, 0.8417, 0.8118,\n",
       "        0.8952, 0.8557, 0.9111, 0.8163, 0.8547, 0.8855, 0.9391, 0.8365, 0.9347,\n",
       "        1.0936, 0.8878, 0.8785, 0.8496, 0.9253, 0.8381, 0.8305, 1.0572, 0.8923,\n",
       "        0.8994, 0.9150, 0.8096, 0.8383, 0.9121, 0.8519, 1.1271, 0.8432, 0.8482,\n",
       "        0.8541, 0.9307, 0.8940, 1.0545, 0.8815, 0.9003, 0.9503, 0.9456, 0.8959,\n",
       "        0.8218, 0.8547, 0.9017, 0.7251, 0.8702, 0.8585, 0.9241, 0.9931, 0.9213,\n",
       "        0.8248, 0.9110, 0.8512, 0.9553, 0.9018, 0.8886, 0.9120, 0.8518, 0.8691,\n",
       "        0.8726, 1.0674, 0.9154, 0.8358, 0.8782, 0.8076, 0.8120, 0.9652, 0.8301,\n",
       "        0.8620, 0.8838, 0.9085, 0.8883, 0.8218, 0.8965, 0.9435, 0.9120, 0.8243,\n",
       "        0.9455, 0.9320, 0.8308, 0.8459, 1.0406, 0.8725, 0.9601, 0.8739, 0.9456,\n",
       "        0.9441, 0.9818, 0.9373, 0.9909, 0.8669, 0.8815, 0.8988, 0.9158, 0.8190,\n",
       "        0.8951, 0.8880, 1.0253, 0.8752, 0.9328, 0.9353, 1.0175, 0.9124, 0.8279,\n",
       "        0.9657, 0.8072, 0.9595, 0.9156, 0.9118, 0.8639, 0.9445, 0.9896, 0.8319,\n",
       "        0.8255, 0.8804, 0.8149, 0.9128, 1.1112, 1.0896, 0.7762, 0.8137, 0.9300,\n",
       "        0.8450, 0.8411, 0.9598, 0.8348, 0.8779, 0.8797, 0.8859, 0.8866, 0.8366,\n",
       "        0.9524, 0.9232, 0.8301, 0.8738, 0.6949, 0.8509, 0.8051, 0.8805, 0.8914,\n",
       "        0.9058, 0.9638, 0.8957, 0.9420, 1.0791, 0.9215, 0.8918, 0.8495, 0.8840,\n",
       "        0.8477, 0.8268, 0.9393, 1.1126, 0.8945, 0.8918, 0.8598, 0.7657, 0.8863,\n",
       "        0.8263, 0.8588, 0.8964, 0.9891, 0.9100, 0.9704, 0.8440, 0.9520, 0.8744,\n",
       "        0.9138, 0.8041, 0.9062, 0.8303, 0.8724, 0.8966, 0.9065, 0.8836, 0.8766,\n",
       "        0.8690, 1.1743, 0.8985, 0.8823, 0.8596, 0.9664, 0.8848, 0.8929, 0.8394,\n",
       "        0.9177, 0.9467, 0.9408, 0.9272, 0.8723, 0.8445, 0.8772, 0.8404, 0.8136,\n",
       "        0.8556, 0.7843, 0.8157, 0.9161, 0.9942, 0.8638, 0.7157, 1.0179, 0.9858,\n",
       "        0.9359, 0.9338, 1.0921, 0.8350, 0.9569, 1.0254, 0.9231, 0.7949, 0.8038,\n",
       "        0.8191, 0.8579, 0.8957, 0.9562, 0.8671, 0.8970, 0.9008, 0.8886, 0.8667,\n",
       "        0.8377, 0.8046, 1.0746, 1.0059, 0.9380, 0.8726, 1.0192, 0.9040])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.squeeze().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaptiveAvgPool2d函数理解：指定feature map的输出大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "inputs = torch.randn(1, 64, 8, 9)\n",
    "output = m(inputs)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras(2.2.5版本，tf版本为1.13.1) bottleneck feature特征提取，mobilenet会提示找不到膨胀卷积\n",
    "1. 直观方法是加载预训练模型时，不加载分类层，详见[这里](https://gist.github.com/takahish/eab7d2923ab30d7c925061da60524db3)\n",
    "2. 定义模型的输入和输出节点，详见[这里](https://github.com/keras-team/keras/issues/8418)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottneck_feature_ks = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image (file):\n",
    "    im_resized = image.load_img(file, target_size = (224,224))\n",
    "    img_array = image.img_to_array(im_resized)\n",
    "    image_array_expanded = np.expand_dims(img_array, axis = 0)\n",
    "    return image_array_expanded\n",
    "img = prepare_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2048)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = bottneck_feature_ks.predict(preprocess_input(img))\n",
    "(features.squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.flatten().shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
